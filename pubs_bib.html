<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
<title>pubs.bib</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="bibtex2html">
</head>

<body>
<h1>pubs.bib</h1><a name="noroozi2017verifying"></a><pre>
@article{<a href="pubs.html#noroozi2017verifying">noroozi2017verifying</a>,
  title = {Verifying Weak Probabilistic Noninterference},
  author = {Noroozi, Ali A. and Karimpour, Jaber and Isazadeh, Ayaz and Lotfi, Shahriar},
  journal = {INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS},
  volume = {8},
  number = {10},
  pages = {196--206},
  year = {2017},
  publisher = {SCIENCE \& INFORMATION SAI ORGANIZATION LTD 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND},
  abstract = {
            Weak probabilistic noninterference is a security property for enforcing confidentiality in multi-threaded programs. 
            It aims to guarantee secure flow of information in the program and ensure that sensitive information does not leak 
            to attackers. In this paper, the problem of verifying weak probabilistic noninterference by leveraging formal methods, 
            in particular algorithmic verification, is discussed. Behavior of multi-threaded programs is modeled using probabilistic 
            Kripke structures and formalize weak probabilistic noninterference in terms of these structures. Then, a verification 
            algorithm is proposed to check weak probabilistic noninterference. The algorithm uses an abstraction technique to compute 
            quotient space of the program with respect to an equivalence relation called weak probabilistic bisimulation and does 
            a simple check to decide whether the security property is satisfied or not. The progress made is demonstrated by a 
            real-world case study. It is expected that the proposed approach constitutes a significant step towards more widely 
            applicable secure information flow analysis.
           }
}
</pre>

<a name="karimpour2015verifying"></a><pre>
@inproceedings{<a href="pubs.html#karimpour2015verifying">karimpour2015verifying</a>,
  author = {Karimpour, Jaber
and Isazadeh, Ayaz
and Noroozi, Ali A.},
  editor = {Federrath, Hannes
and Gollmann, Dieter},
  title = {Verifying Observational Determinism},
  booktitle = {ICT Systems Security and Privacy Protection},
  year = {2015},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {82--93},
  isbn = {978-3-319-18467-8},
  abstract = {This paper proposes an approach to verify information flow security of concurrent programs. It discusses a hyperproperty 
         called observational determinism which aims to ensure secure information flow in concurrent programs, and proves how this 
         hyperproperty can be verified by stutter equivalence checking. More precisely, it defines observational determinism in 
         terms of stutter equivalence of all traces having the same low initial value and shows how stutter trace equivalence can 
         be verified by computing a divergence stutter bisimulation quotient. The approach is illustrated by verifying a small example.}
}
</pre>

<a name="karimpour2014modified"></a><pre>
@article{<a href="pubs.html#karimpour2014modified">karimpour2014modified</a>,
  title = {Modified Bitwise Hill Crypto System},
  author = {Karimpour, Jaber and Aghdasifam, Masoud and Noroozi, Ali A.},
  volume = {12},
  number = {2},
  pages = {11--15},
  year = {2014},
  publisher = {The CSI Journal on Computer Science and Engineering},
  abstract = {
             Hill Cipher (HC) is a matrix-based polygraph symmetric data encryption method. In 2011, Desoky et al. proposed 
             the Bitwise Hill Crypto System (BHC) which is based on bit arithmetic. In this paper, we analyze BHC and show that 
             it is insecure. Then, we propose a new modification using chaotic maps which provides better security.
  }
}
</pre>

<a name="karimpour2013modified"></a><pre>
@conference{<a href="pubs.html#karimpour2013modified">karimpour2013modified</a>,
  title = {Modified Bitwise Hill Crypto System},
  author = {Karimpour, Jaber and Aghdasifam, Masoud and Noroozi, Ali A.},
  year = {2013},
  booktitle = {The 2013 CSI International Symposium on Computer Science and Software Engineering},
  abstract = {
             Hill Cipher (HC) is a matrix-based polygraph symmetric data encryption method. In 2011, Desoky et al. proposed 
             the Bitwise Hill Crypto System (BHC) which is based on bit arithmetic. In this paper, we analyze BHC and show that 
             it is insecure. Then, we propose a new modification using chaotic maps which provides better security.
  }
}
</pre>

<a name="karimpour2013formal"></a><pre>
@article{<a href="pubs.html#karimpour2013formal">karimpour2013formal</a>,
  author = {Jaber Karimpour and Robab Alyari and Ali A. Noroozi},
  journal = {IET Software},
  title = {Formal framework for specifying dynamic reconfiguration of adaptive systems},
  year = {2013},
  volume = {7},
  number = {5},
  pages = {258-270},
  keywords = {adaptive systems;formal specification;software architecture;synchronisation;vectors;synchronisation vectors;adaptor system;mathematical model;system architecture;adaptation contract;change reconfiguration;change problem;software adaptation techniques;software systems;adaptive systems;dynamic reconfiguration specification;formal framework},
  doi = {10.1049/iet-sen.2012.0163},
  issn = {1751-8806},
  month = {October},
  abstract = {
           In the real-world, there are many types of software systems and software engineers always deal with changes. The value
           of large systems decreases significantly as the requirements and operational environment change over time. Modern software
           systems are expected to have dynamic reconfigurations to cope with failure and changes. Software adaptation techniques try
           to overcome the change problem by reconfiguration. In this study, at first, the authors present a formal framework to represent
           the whole system and then, build a mathematical model called ‘adaptor’ based on adaptation contract and system architecture.
           The adaptor is used to define automatic fit between two different components of the system. Finally, for specifying the whole
           adaptor system the authors will introduce adaptor network using synchronisation vectors.
 }
}
</pre>

<a name="karimpour2012impact"></a><pre>
@article{<a href="pubs.html#karimpour2012impact">karimpour2012impact</a>,
  title = {The impact of feature selection on web spam detection},
  author = {Karimpour, Jaber and Noroozi, Ali A and Abadi, Adeleh},
  journal = {International Journal of Intelligent Systems and Applications},
  volume = {4},
  number = {9},
  pages = {61},
  year = {2012},
  publisher = {Modern Education and Computer Science Press},
  abstract = {
             Search engine is one of the most important tools for managing the massive amount of distributed web content. Web spamming tries to 
             deceive search engines to rank some pages higher than they deserve. Many methods have been proposed to combat web spamming and 
             to detect spam pages. One basic one is using classification, i.e., learning a classification model for classifying web pages 
             to spam or non-spam. This work tries to select the best feature set for classification of web spam using imperialist competitive 
             algorithm and genetic algorithm. Imperialist competitive algorithm is a novel optimization algorithm that is inspired by socio-political 
             process of imperialism in the real world. Experiments are carried out on WEBSPAM-UK2007 data set, which show feature selection improves 
             classification accuracy, and imperialist competitive algorithm outperforms GA.
  }
}
</pre>

<a name="karimpour2012web"></a><pre>
@article{<a href="pubs.html#karimpour2012web">karimpour2012web</a>,
  title = {Web Spam Detection by Learning from Small Labeled Samples},
  author = {Karimpour, Jaber and Noroozi, Ali A and Alizadeh, Somayeh},
  journal = {International Journal of Computer Applications},
  volume = {50},
  number = {21},
  pages = {1--5},
  year = {2012},
  abstract = {
             Web spamming tries to deceive search engines to rank some pages higher than they deserve. Many methods have been proposed to combat web spamming 
             and to detect spam pages. One basic method is using classification, i.e., learning a classification model from previously labeled training data 
             and using this model for classifying web pages to spam or non-spam. A drawback of this method is that manually labeling a large number of web pages 
             to generate the training data can be biased, non-accurate, labor intensive and time consuming. In this paper, we are going to propose a new method to
             resolve this drawback by using semi-supervised learning to automatically label the training data. To do this, we incorporate Expectation-Maximization
             algorithm that is an efficient and an important algorithm of semi-supervised learning. Experiments are carried out on the real web spam data, which 
             show the new method, performs very well in practice.
  }
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
</body>
</html>
